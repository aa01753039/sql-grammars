# Grammar-Constrained Decoding in Text-to-SQL

This repository contains the main executable script and resources for my dissertation titled "Enhancing SQL Query Generation: The Role of Grammar-Constrained Decoding in Large Language Models". The project explores the application of grammar-constrained decoding to improve the accuracy and reliability of SQL query generation from natural language prompts.

## Repository Structure

- **`sql_inference.py`**: The main executable script for running the Text-to-SQL inference with different runtime configurations.
- **`requirements.txt`**: Lists the Python dependencies required to run the project.
- **`grammars/`**: Contains `.ebnf` grammar files, including both the base and embedded grammars.
- **`outputs/`**: Stores the generated SQL outputs when running the system with the Llama 3.1 model under different configurations.
- **`evaluation/`**: Includes the Spider evaluation results for the SQL outputs generated by the system.

## Runtime Configurations

The `sql_inference.py` script supports three different runtime configurations, each offering a different approach to SQL query generation:

1. **No Constrained Decoding**: 
   - This runtime type does not utilize any grammar constraints during SQL generation.
   - **Required Arguments**:
     - `--model_id`: The Hugging Face repository ID of the LLM model (e.g., Llama 3.1).
     - `--db_path`: The path to the database folder.
     - `--prompt_template`: The prompt template to guide the model in generating SQL queries.
     - `--questions_file`: Path to the JSON file containing the natural language questions.
     - `--predicted_path`: Directory where the predicted SQL queries will be stored.

2. **Constrained Decoding with Base Grammar**:
   - In this configuration, the model generates SQL queries guided by a predefined base grammar.
   - **Required Arguments**: Same as "No Constrained Decoding", with the addition of:
     - `--grammar_template_path`: The path to the base grammar file (.ebnf) that constrains the decoding process.

3. **Constrained Decoding with Embedded Grammar**:
   - This runtime type uses an embedded grammar, which is dynamically constructed based on the database schema.
   - **Required Arguments**: Same as "Constrained Decoding with Base Grammar", with the addition of:
     - `--grammar_directory`: The directory where the embedded grammar files will be stored and retrieved.

## Usage

To run the script, use the following command line:

```bash
python sql_inference.py --model_id <model_id> --db_path <db_path> --prompt_template <prompt_template> --questions_file <questions_file> --predicted_path <predicted_path> [--grammar_template_path <grammar_template_path>] [--grammar_directory <grammar_directory>]
```

Ensure to replace the placeholders with the actual paths and parameters relevant to your setup. The `grammar_template_path` and `grammar_directory` arguments are optional, depending on the runtime configuration you wish to use.

## Evaluation

The results of running the script using the Llama 3.1 model with different runtime types are stored in the `outputs/` directory. The evaluation results, which compare the generated SQL queries to ground truth using the Spider benchmark, can be found in the `evaluation/` directory.

## Dependencies

Install the required Python packages using:

```bash
pip install -r requirements.txt
```

## License

This project is licensed under the MIT License.

## Contact

For any questions or inquiries, please feel free to reach out.

